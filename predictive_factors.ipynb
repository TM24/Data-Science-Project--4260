{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You WILL need the following in bash:\n",
    "#    pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "# MAKE SURE EVERYTHING IS UP TO DATE IF PREDOWNLOADED!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General things for functions\n",
    "import numpy as np # Numerical commands\n",
    "import pandas as pd # Data manipulation\n",
    "\n",
    "#Visualization tools for plotting\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Machine learning parts itself\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing of the files. Cleaned prior to import.\n",
    "testAway = pd.read_csv('testDataV3_away.txt')\n",
    "testHome = pd.read_csv('testDataV3_home.txt')\n",
    "testY = pd.read_csv('testDataV3_y.txt') # Used to check prediction accuracy. Contains home_win, draw, away_win values\n",
    "\n",
    "trainAway = pd.read_csv('trainDataV3_away.txt') # Different IDS than test\n",
    "trainHome = pd.read_csv('trainDataV3_home.txt')\n",
    "trainY = pd.read_csv('trainDataV3_y.txt') # In training, use this to understand what difference in values leads to a win, draw, loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to distinguish home and away stats\n",
    "trainAway = trainAway.add_prefix(\"AWAY_\")\n",
    "trainHome = trainHome.add_prefix(\"HOME_\")\n",
    "\n",
    "# Ensure features match in the correct order for concatenation\n",
    "selected_features = ['TEAM_SHOTS_TOTAL_season_sum', 'TEAM_SHOTS_ON_TARGET_season_sum',\n",
    "                     'TEAM_PASSES_season_sum', 'TEAM_SUCCESSFUL_PASSES_season_sum',\n",
    "                     'TEAM_SAVES_season_sum', 'TEAM_CORNERS_season_sum',\n",
    "                     'TEAM_FOULS_season_sum', 'TEAM_YELLOWCARDS_season_sum',\n",
    "                     'TEAM_REDCARDS_season_sum', 'TEAM_ATTACKS_season_sum',\n",
    "                     'TEAM_DANGEROUS_ATTACKS_season_sum', 'TEAM_GOALS_season_sum']\n",
    "\n",
    "# Create full feature lists with correct prefixes\n",
    "away_features = [\"AWAY_\" + col for col in selected_features]\n",
    "home_features = [\"HOME_\" + col for col in selected_features]\n",
    "\n",
    "# Concatenate home and away features\n",
    "X_train = pd.concat([trainAway[away_features], trainHome[home_features]], axis=1)\n",
    "\n",
    "# Define the target variable\n",
    "y_train = trainY[['HOME_WINS', 'DRAW', 'AWAY_WINS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize a dictionary to store models and their predictions\n",
    "y_train_pred = {}\n",
    "y_val_pred = {}\n",
    "\n",
    "# Train Logistic Regression models\n",
    "for target in y_train.columns:\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train[target])\n",
    "\n",
    "    # Predict with trainig and validation\n",
    "    y_train_pred[target] = model.predict(X_train_scaled)\n",
    "    y_val_pred[target] = model.predict(X_val_scaled)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train[target], y_train_pred[target])\n",
    "    val_accuracy = accuracy_score(y_val[target], y_val_pred[target])\n",
    "\n",
    "    print(f\"Training Accuracy for {target}: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy for {target}: {val_accuracy:.4f}\")  # This should improve\n",
    "\n",
    "    # Feature importance analysis using Logistic Regression coefficients\n",
    "    importance = np.abs(model.coef_).flatten()  # Use absolute values for coefficients to measure importance\n",
    "    features = X_train.columns\n",
    "    importance_df = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot feature importance for home_win/draw/away_win\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=importance_df['Feature'], y=importance_df['Importance'])\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title(f'Feature Importance for {target}')\n",
    "    plt.xticks(rotation=45, ha='right')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below files are to be unused, yet had a previous function prior to better understanding of the desired model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def calculate_game_stats(df):\n",
    "#     # This will calculate the total number of games played\n",
    "#     df['TOTAL_GAMES_PLAYED'] = df['TEAM_GAME_WON_season_sum'] + df['TEAM_GAME_DRAW_season_sum'] + df['TEAM_GAME_LOST_season_sum']\n",
    "    \n",
    "#     # Calculate Win perctengae: Wins / (total of all games)\n",
    "#     # This is of course to determine \"good\" compared to \"bad\" teams and see what factors are different\n",
    "#     df['WIN_PERCENTAGE'] = (df['TEAM_GAME_WON_season_sum'] / df['TOTAL_GAMES_PLAYED']) *100\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "# trainHome = calculate_game_stats(trainHome)\n",
    "# trainAway = calculate_game_stats(trainAway)\n",
    "# testHome = calculate_game_stats(testHome)\n",
    "# testAway = calculate_game_stats(testAway)\n",
    "\n",
    "\n",
    "# print(\"Train Home Data with Stats:\")\n",
    "# print(trainHome[['TEAM_GAME_WON_season_sum', 'TEAM_GAME_DRAW_season_sum', 'TEAM_GAME_LOST_season_sum', 'TOTAL_GAMES_PLAYED', 'WIN_PERCENTAGE']].head())\n",
    "\n",
    "# print(\"\\nTrain Away Data with Stats:\")\n",
    "# print(trainAway[['TEAM_GAME_WON_season_sum', 'TEAM_GAME_DRAW_season_sum', 'TEAM_GAME_LOST_season_sum', 'TOTAL_GAMES_PLAYED', 'WIN_PERCENTAGE']].head())\n",
    "\n",
    "\n",
    "# # Below was a simple test to ensure the test data win loss columns were created\n",
    "# # This is not to be used until model evaluation with the training data\n",
    "\n",
    "# # print(\"\\nTest Home Data with Stats:\")\n",
    "# # print(testHome[['TEAM_GAME_WON_season_sum', 'TEAM_GAME_DRAW_season_sum', 'TEAM_GAME_LOST_season_sum', 'TOTAL_GAMES_PLAYED', 'WIN_LOSS_RATIO']].head())\n",
    "\n",
    "# # print(\"\\nTest Away Data with Stats:\")\n",
    "# # print(testAway[['TEAM_GAME_WON_season_sum', 'TEAM_GAME_DRAW_season_sum', 'TEAM_GAME_LOST_season_sum', 'TOTAL_GAMES_PLAYED', 'WIN_LOSS_RATIO']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_high_vs_low_winrate(df):\n",
    "#     # Median win #\n",
    "#     median_win_percentage = df['WIN_PERCENTAGE'].median()\n",
    "    \n",
    "#     # High and low win rate groups (for comparison)\n",
    "#     high_winrate = df[df['WIN_PERCENTAGE'] >= median_win_percentage]\n",
    "#     low_winrate = df[df['WIN_PERCENTAGE'] < median_win_percentage]\n",
    "    \n",
    "#     # List of statistics to compare\n",
    "#     stats_to_compare = [\n",
    "#         'TEAM_SHOTS_TOTAL_season_sum', 'TEAM_SHOTS_ON_TARGET_season_sum',\n",
    "#         'TEAM_PASSES_season_sum', 'TEAM_SUCCESSFUL_PASSES_season_sum',\n",
    "#         'TEAM_SAVES_season_sum', 'TEAM_CORNERS_season_sum',\n",
    "#         'TEAM_FOULS_season_sum', 'TEAM_YELLOWCARDS_season_sum',\n",
    "#         'TEAM_REDCARDS_season_sum', 'TEAM_ATTACKS_season_sum',\n",
    "#         'TEAM_DANGEROUS_ATTACKS_season_sum', 'TEAM_GOALS_season_sum'\n",
    "#     ]\n",
    "    \n",
    "#     # Average stats per high/low team\n",
    "#     high_winrate_stats = high_winrate[stats_to_compare].mean()\n",
    "#     low_winrate_stats = low_winrate[stats_to_compare].mean()\n",
    "    \n",
    "#     # Find the difference to see what matters\n",
    "#     percentage_diff = ((high_winrate_stats - low_winrate_stats) / low_winrate_stats) * 100\n",
    "    \n",
    "#     sorted_diff = percentage_diff.abs().sort_values(ascending=False)\n",
    "\n",
    "#     print(\"Top differences between high and low win rate teams:\")\n",
    "#     for stat in sorted_diff.index[:10]:  # Top 10 differences\n",
    "#         diff = percentage_diff[stat]\n",
    "#         print(f\"{stat}: {diff:.2f}% {'higher' if diff > 0 else 'lower'} for high win rate teams\")\n",
    "    \n",
    "#     # Shows the top 5 and their average values for comparison\n",
    "#     top_5_stats = sorted_diff.index[:5]\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     x = range(len(top_5_stats))\n",
    "#     plt.bar(x, high_winrate_stats[top_5_stats], width=0.35, align='center', label='High Win Rate')\n",
    "#     plt.bar(x, low_winrate_stats[top_5_stats], width=0.35, align='edge', label='Low Win Rate')\n",
    "#     plt.xlabel('Statistics')\n",
    "#     plt.ylabel('Average Value')\n",
    "#     plt.title('Top 5 Differences: High vs Low Win Rate Teams')\n",
    "#     plt.xticks(x, top_5_stats, rotation=45, ha='right')\n",
    "#     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Run the analysis for both home and away data\n",
    "# print(\"Analysis for Home Teams:\")\n",
    "# analyze_high_vs_low_winrate(trainHome)\n",
    "\n",
    "# print(\"\\nAnalysis for Away Teams:\")\n",
    "# analyze_high_vs_low_winrate(trainAway)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define important features based above\n",
    "# important_features = [\n",
    "#     'TEAM_GOALS_season_sum', 'TEAM_SHOTS_ON_TARGET_season_sum', \n",
    "#     'TEAM_SUCCESSFUL_PASSES_season_sum', 'TEAM_SHOTS_TOTAL_season_sum',\n",
    "#     'TEAM_PASSES_season_sum', 'TEAM_DANGEROUS_ATTACKS_season_sum',\n",
    "#     'TEAM_CORNERS_season_sum', 'TEAM_ATTACKS_season_sum', 'WIN_PERCENTAGE'\n",
    "# ]\n",
    "\n",
    "# for feature in important_features:\n",
    "#     testHome[feature] = pd.to_numeric(testHome[feature], errors='coerce')\n",
    "#     testAway[feature] = pd.to_numeric(testAway[feature], errors='coerce')\n",
    "\n",
    "# # Function for comparison and therefore prediction\n",
    "# def predict_match():\n",
    "#     # User input\n",
    "#     home_id = int(input(\"Enter Home Team ID (12303-37670): \"))\n",
    "#     away_id = int(input(\"Enter Away Team ID (12303-37670): \"))\n",
    "\n",
    "#     # Ensure ID exists\n",
    "#     if home_id not in testHome['ID'].values or away_id not in testAway['ID'].values:\n",
    "#         print(\"Invalid ID entered. Please try again.\")\n",
    "#         return\n",
    "    \n",
    "#     # Gets the team's important stats\n",
    "#     home_team = testHome[testHome['ID'] == home_id].iloc[0]\n",
    "#     away_team = testAway[testAway['ID'] == away_id].iloc[0]\n",
    "\n",
    "#     # Find the difference for comparison\n",
    "#     comparison = {}\n",
    "#     for feature in important_features:\n",
    "#         comparison[f'{feature}_DIFFERENCE'] = home_team[feature] - away_team[feature]\n",
    "\n",
    "#     print(\"\\nStatistical Comparison (Home - Away):\")\n",
    "#     for feature, diff in comparison.items():\n",
    "#         print(f\"{feature}: {diff:.2f}\")\n",
    "\n",
    "#     # Simple rule-based prediction. Could use tweaking but I need help with that\n",
    "#     if comparison['WIN_PERCENTAGE_DIFFERENCE'] > 0 and \\\n",
    "#        comparison['TEAM_GOALS_season_sum_DIFFERENCE'] > 0 and \\\n",
    "#        comparison['TEAM_SHOTS_ON_TARGET_season_sum_DIFFERENCE'] > 0:\n",
    "#         predicted_winner = \"Home Team\"\n",
    "#     else:\n",
    "#         predicted_winner = \"Away Team\"\n",
    "\n",
    "#     print(f\"\\nPredicted Winner: {predicted_winner}\")\n",
    "\n",
    "# predict_match()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
