{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook Cleans our Data\n",
    "\n",
    "### This is quite a lot of data so it may take some time to complete depending on hardware resources\n",
    "\n",
    "### I would recommend only having this notbook open and closing all other applications when running, unless you have good specs on desktop\n",
    "\n",
    "#### Feel free to change the values to whatever you want if you are experementing with removing other data, like _std, _5_last_games, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and clean data\n",
    "def load_and_clean_data(file_path):\n",
    "    \"\"\"Load a dataset and apply cleaning steps.\n",
    "    Removes STD, season average, and last 5 matched sum\n",
    "    Fills NULL/nan values with 0/zero\n",
    "    and drops rows with more than 20% NULL values we cna change this \n",
    "    I just felt like 20% seemed right\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.drop(df.filter(regex='_std$|_season_average$|5_last_match_sum$').columns, axis=1)\n",
    "        \n",
    "        # Drop rows where more than 80% of the data is missing\n",
    "        threshold = int(0.20 * len(df.columns))  # Keep rows with at least 80% non-null values\n",
    "        df = df.dropna(thresh=threshold)\n",
    "\n",
    "        # Fill remaining missing values with zero\n",
    "        df = df.fillna(0)\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to reshape player data (convert multiple rows per ID into a single row)\n",
    "def reshape_player_data(player_df):\n",
    "    \"\"\"Convert player stats from multiple rows to a single row per ID.\"\"\"\n",
    "    if player_df is None:\n",
    "        return None\n",
    "\n",
    "    # Add a unique number to each player's stats for a given ID\n",
    "    player_df[\"player_number\"] = player_df.groupby(\"ID\").cumcount() + 1\n",
    "\n",
    "    # Reshape using pivot_table (each player gets a numbered column)\n",
    "    player_df = player_df.pivot(index=\"ID\", columns=\"player_number\")\n",
    "    \n",
    "    # Flatten MultiIndex columns\n",
    "    player_df.columns = [f\"{col[0]}_P{col[1]}\" for col in player_df.columns]\n",
    "    \n",
    "    # Reset index so ID is a column again\n",
    "    player_df = player_df.reset_index()\n",
    "    \n",
    "    return player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and clean data\n",
    "def clean_data_V2(df):\n",
    "    \"\"\"Load a dataset and apply cleaning steps.\n",
    "    remove P15-27\n",
    "    and POSITION\"\"\"\n",
    "    try:\n",
    "        df = df.drop(df.filter(regex='P2[0-7]$|^POSITION|P1[5-9]$|^TEAM_NAME|^LEAGUE|^PLAYER_NAME').columns, axis=1)\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading {df}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to merge team and reshaped player data\n",
    "def merge_team_and_players(team_path, player_path, output_path):\n",
    "    \"\"\"Merge a team dataset with its players into a single row per ID and save to file.\"\"\"\n",
    "    print(f\"Processing and saving: {output_path}\")\n",
    "\n",
    "    # Load and clean data\n",
    "    team_df = load_and_clean_data(team_path)\n",
    "    player_df = load_and_clean_data(player_path)\n",
    "\n",
    "    if team_df is None or player_df is None:\n",
    "        print(f\"Skipping {output_path} due to missing data.\")\n",
    "        return\n",
    "\n",
    "    # Reshape player stats\n",
    "    reshaped_players = reshape_player_data(player_df)\n",
    "\n",
    "    # Merge team stats with reshaped player stats (1 row per ID)\n",
    "    merged_df = pd.merge(team_df, reshaped_players, on='ID', how='left')\n",
    "    \n",
    "    cleaned_v2 = clean_data_V2(merged_df)\n",
    "\n",
    "    # Save final dataset\n",
    "    cleaned_v2.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {output_path} ({cleaned_v2.shape[0]} rows, {cleaned_v2.shape[1]} columns)\")\n",
    "\n",
    "    # Free up memory\n",
    "    del team_df, player_df, reshaped_players, merged_df, cleaned_v2\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "data_paths = {\n",
    "    \"train_home_team\": \"C:/Path/To/Data/Train_Data/train_home_team_statistics_df.csv\",\n",
    "    \"train_home_player\": \"C:/Path/To/Data/Train_Data/train_home_player_statistics_df.csv\",\n",
    "    \"train_away_team\": \"C:/Path/To/Data/Train_Data/train_away_team_statistics_df.csv\",\n",
    "    \"train_away_player\": \"C:/Path/To/Data/Train_Data/train_away_player_statistics_df.csv\",\n",
    "    \"test_home_team\": \"C:/Path/To/Data/Test_Data/test_home_team_statistics_df.csv\",\n",
    "    \"test_home_player\": \"C:/Path/To/Data/Test_Data/test_home_player_statistics_df.csv\",\n",
    "    \"test_away_team\": \"C:/Path/To/Data/Test_Data/test_away_team_statistics_df.csv\",\n",
    "    \"test_away_player\": \"C:/Path/To/Data/Test_Data/test_away_player_statistics_df.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CLeaning Columns\n",
    "# Create output directory\n",
    "output_dir = \"C:/Path/To/Data/cleanedData/TestingCleanedDataGroupTest\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Merge and save Home datasets separately\n",
    "merge_team_and_players(data_paths[\"train_home_team\"], data_paths[\"train_home_player\"], os.path.join(output_dir, \"train_merged_home.csv\"))\n",
    "merge_team_and_players(data_paths[\"test_home_team\"], data_paths[\"test_home_player\"], os.path.join(output_dir, \"test_merged_home.csv\"))\n",
    "\n",
    "# Merge and save Away datasets separately\n",
    "merge_team_and_players(data_paths[\"train_away_team\"], data_paths[\"train_away_player\"], os.path.join(output_dir, \"train_merged_away.csv\"))\n",
    "merge_team_and_players(data_paths[\"test_away_team\"], data_paths[\"test_away_player\"], os.path.join(output_dir, \"test_merged_away.csv\"))\n",
    "\n",
    "print(\"All datasets merged and saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
